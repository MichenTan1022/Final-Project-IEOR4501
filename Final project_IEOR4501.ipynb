{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49b47bf",
   "metadata": {},
   "source": [
    "## Part 0: Setup\n",
    "In this part we set up some basic environment and variables needed for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe6aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import bs4\n",
    "import math\n",
    "import requests\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keplergl as kg\n",
    "from scipy import stats\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed8c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables needed\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "WEATHER_CSV = [\"weather-2009.csv\", \"weather-2010.csv\", \"weather-2011.csv\", \n",
    "               \"weather-2012.csv\", \"weather-2013.csv\", \"weather-2014.csv\", \"weather-2015.csv\"]\n",
    "ZONE_PATH = \"taxi_zones.shp\"\n",
    "\n",
    "NY_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE = \"sqlite:///project.db\"\n",
    "SCHEMA_FILE = \"schema.sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1366081",
   "metadata": {},
   "outputs": [],
   "source": [
    "Taxi_zone = gpd.read_file(ZONE_PATH)\n",
    "Taxi_zone = Taxi_zone.to_crs(4326)\n",
    "Taxi_zone['longitude'] = Taxi_zone.centroid.x  \n",
    "Taxi_zone['latitude'] = Taxi_zone.centroid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d022e5",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "### Yellow Taxi trip data: Downloading, Cleaning, Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b889eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_html() -> bytes:\n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019bea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_parquet_links() -> list:\n",
    "    links = []\n",
    "    pattern = r\"yellow_tripdata_2009|yellow_tripdata_201[0-4]|yellow_tripdata_2015-0[1-6]\"\n",
    "    soup = bs4.BeautifulSoup(get_taxi_html(),'html.parser')\n",
    "    for a in soup.find_all(\"a\",href = True):\n",
    "        link_text = a.get(\"href\")\n",
    "        matches = re.findall(pattern,link_text)\n",
    "        if matches:\n",
    "            links.append(link_text)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef193e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_taxi_data_download_clean_sample(url: str) -> pd.core.frame.DataFrame:\n",
    "    parquet_name = url.split(\"/\")[-1]\n",
    "\n",
    "    # download if it doesn't exist\n",
    "    if not os.path.exists(parquet_name):\n",
    "        print(f\"Downloading parquet for {parquet_name[16:23]}.\")\n",
    "        file = requests.get(url)\n",
    "        with open(parquet_name , \"wb\") as f:\n",
    "            f.write(file.content)\n",
    "    \n",
    "    # load data from parquet file\n",
    "    data = pd.read_parquet(parquet_name)\n",
    "    print(f\"Cleaning data for {parquet_name[16:23]}.\")\n",
    "    \n",
    "    # 为了不占用太多内存，读一个删一个，最后提交之前要删掉\n",
    "    os.remove(parquet_name) \n",
    "    print(f\"Parquet for {parquet_name[16:23]} is removed.\")\n",
    "    \n",
    "    # looking up the latitude and longitude for some months where only location IDs are given for pickups and dropoffs\n",
    "    # keep NaNs if exists\n",
    "    if \"PULocationID\" in data.columns:\n",
    "        data[\"pickup_latitude\"] = data[\"PULocationID\"].map(Taxi_zone[\"latitude\"], na_action = \"ignore\")\n",
    "        data[\"pickup_longitude\"] = data[\"PULocationID\"].map(Taxi_zone[\"longitude\"], na_action = \"ignore\")\n",
    "        data[\"dropoff_latitude\"] = data[\"DOLocationID\"].map(Taxi_zone[\"latitude\"], na_action = \"ignore\")\n",
    "        data[\"dropoff_longitude\"] = data[\"DOLocationID\"].map(Taxi_zone[\"longitude\"], na_action = \"ignore\")\n",
    "    \n",
    "    # normalize column names\n",
    "    rename_dict = {\n",
    "        \"VendorID\" : \"vendor_id\",\n",
    "        \"tpep_pickup_datetime\" : \"pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\" : \"dropoff_datetime\",\n",
    "        \"RatecodeID\" : \"rate_code\",\n",
    "        \"Trip_Pickup_DateTime\" : \"pickup_datetime\",\n",
    "        \"Trip_Dropoff_DateTime\" : \"dropoff_datetime\",\n",
    "        \"Start_Lon\" : \"pickup_longitude\",\n",
    "        \"Start_Lat\" : \"pickup_latitude\",\n",
    "        \"End_Lon\" : \"dropoff_longitude\",\n",
    "        \"End_Lat\" : \"dropoff_latitude\",\n",
    "        \"Fare_Amt\" : \"fare_amount\",\n",
    "        \"Tip_Amt\" : \"tip_amount\",\n",
    "        \"Tolls_Amt\" : \"tolls_amount\",\n",
    "        \"Total_Amt\" : \"total_amount\"\n",
    "    }\n",
    "    data.rename(columns = rename_dict, inplace = True)\n",
    "    \n",
    "    # remove the trips that the location IDs are be valid\n",
    "    data.dropna(subset=[\"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\"],inplace = True)\n",
    "    \n",
    "    # remove invalid data points\n",
    "    data = data[data[\"total_amount\"] > 0]\n",
    "    \n",
    "    # normalize and use appropriate column types for the respective data\n",
    "    data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"])\n",
    "    data[\"dropoff_datetime\"] = pd.to_datetime(data[\"dropoff_datetime\"])\n",
    "    data = data.astype({\"pickup_latitude\": \"float64\",\"pickup_longitude\": \"float64\",\\\n",
    "                        \"dropoff_latitude\": \"float64\",\"dropoff_longitude\": \"float64\",\"tip_amount\": \"float64\"})\n",
    "    \n",
    "    # remove unnecessary columns and only keeping columns needed\n",
    "    data = data[[\"pickup_datetime\",\"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\",\"tip_amount\"]]\n",
    "    \n",
    "    # remove trips that start and/or end outside of NY\n",
    "    data = data[(data[\"pickup_latitude\"] >= NY_COORDS[0][0]) & (data[\"pickup_latitude\"] <= NY_COORDS[1][0])]\n",
    "    data = data[(data[\"pickup_longitude\"] >= NY_COORDS[0][1]) & (data[\"pickup_longitude\"] <= NY_COORDS[1][1])]\n",
    "    data = data[(data[\"dropoff_latitude\"] >= NY_COORDS[0][0]) & (data[\"dropoff_latitude\"] <= NY_COORDS[1][0])]\n",
    "    data = data[(data[\"dropoff_longitude\"] >= NY_COORDS[0][1]) & (data[\"dropoff_longitude\"] <= NY_COORDS[1][1])]\n",
    "    \n",
    "    # Sampling\n",
    "    # Uber dataset consists of 200000 data points\n",
    "    # Therefore, we need 200000/78 ~ 2564 data points from each month\n",
    "    data = data.sample(2564)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dcc595",
   "metadata": {},
   "source": [
    "### Yellow Taxi trip data: Filling (Distance)\n",
    "\n",
    "We calculate the distance between pickup location and dropoff location using the Haversine Formula:\n",
    "\n",
    "![](https://user-images.githubusercontent.com/2789198/27240436-e9a459da-52d4-11e7-8f84-f96d0b312859.png)\n",
    "\n",
    "where $\\lambda$ and $\\phi$ are the `longitude` and `latitude` of locations respectively, $r$ is the radius of earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6abe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(pu_coord: pd.core.frame.DataFrame, do_coord: pd.core.frame.DataFrame) -> pd.core.series.Series:\n",
    "    \n",
    "    pick_lon = pu_coord[\"pickup_longitude\"].map(math.radians)\n",
    "    pick_lat = pu_coord[\"pickup_latitude\"].map(math.radians)\n",
    "    drop_lon = do_coord[\"dropoff_longitude\"].map(math.radians)\n",
    "    drop_lat = do_coord[\"dropoff_latitude\"].map(math.radians)\n",
    "    \n",
    "    delta_lat = drop_lat - pick_lat\n",
    "    delta_lon = drop_lon - pick_lon\n",
    "    \n",
    "    # Take the average earth radius (km) as r\n",
    "    r = 6371\n",
    "    part_formula = ((delta_lat/2).map(math.sin))**2 + (pick_lat.map(math.cos))*(drop_lat.map(math.cos))*((delta_lon/2).map(math.sin))**2\n",
    "    dist = 2 * r * part_formula.map(math.sqrt).map(math.asin)\n",
    "    \n",
    "    return dist.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547f8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_distance(data: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    pu_coord = data[[\"pickup_longitude\",\"pickup_latitude\"]]\n",
    "    do_coord = data[[\"dropoff_longitude\",\"dropoff_latitude\"]]\n",
    "    data[\"distance\"] = calculate_distance(pu_coord, do_coord)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66491c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_taxi_data(urls: list) -> pd.core.frame.DataFrame:\n",
    "    all_taxi_df = []\n",
    "    for url in urls:\n",
    "        data = monthly_taxi_data_download_clean_sample(url)\n",
    "        data = filling_distance(data)\n",
    "        all_taxi_df.append(data)\n",
    "    \n",
    "    all_data = pd.concat(all_taxi_df)\n",
    "    \n",
    "    return all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
